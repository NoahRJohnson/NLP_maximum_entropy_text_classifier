{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Entropy Text Classifier\n",
    "\n",
    "Classifying Reuters articles following [this](http://tongzhang-ml.org/papers/ir01_textcat.pdf) paper by Zhang and Oles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We'll use the nltk.corpus.reuters corpus of news articles.\n",
    "\n",
    "The Reuters Corpus contains 10,788 news documents totaling 1.3 million words. The documents have been classified into 90 topics, and grouped into training and testing sets.\n",
    "\n",
    "We are going to choose a single category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10788/10788 [00:00<00:00, 29891.31article/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class                                             tokens\n",
      "   -1  (BAHIA, COCOA, REVIEW, Showers, continued, thr...\n",
      "   -1  (COMPUTER, TERMINAL, SYSTEMS, &, lt, ;, CPML, ...\n",
      "   -1  (N, ., Z, ., TRADING, BANK, DEPOSIT, GROWTH, R...\n",
      "   -1  (NATIONAL, AMUSEMENTS, AGAIN, UPS, VIACOM, &, ...\n",
      "   -1  (ROGERS, &, lt, ;, ROG, >, SEES, 1ST, QTR, NET...\n",
      "\n",
      "Class distribution:\n",
      " -1    7231\n",
      " 1     538\n",
      "Name: class, dtype: int64\n",
      "\n",
      "Size of training corpus = 7769 documents\n",
      "Size of testing corpus = 3019 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import reuters\n",
    "from tqdm import tqdm\n",
    "\n",
    "CHOSEN_CATEGORY = 'money-fx'\n",
    "\n",
    "training_articles = []\n",
    "training_labels = []\n",
    "testing_articles = []\n",
    "testing_labels = []\n",
    "\n",
    "# Loop over every document in the corpus\n",
    "for fileid in tqdm(reuters.fileids(), unit='article'):\n",
    "    \n",
    "    # Binary categorization\n",
    "    if CHOSEN_CATEGORY in reuters.categories(fileid):\n",
    "        label = 1\n",
    "    else:\n",
    "        label = -1\n",
    "\n",
    "    # Extract list of tokens for this document\n",
    "    article = reuters.words(fileid)\n",
    "    \n",
    "    # Put data in train or test set\n",
    "    if 'training' in fileid:\n",
    "        training_articles.append(article)\n",
    "        training_labels.append(label)\n",
    "    elif 'test' in fileid:\n",
    "        testing_articles.append(article)\n",
    "        testing_labels.append(label)\n",
    "    else:\n",
    "        print(\"Unrecognized document %s\" % fileid)\n",
    "\n",
    "# Create Pandas data frames\n",
    "training_corpus = pd.DataFrame({'tokens': training_articles, 'class': training_labels})\n",
    "testing_corpus = pd.DataFrame({'tokens': testing_articles, 'class': testing_labels})\n",
    "\n",
    "print(training_corpus.head().to_string(index=False))\n",
    "\n",
    "class_document_count = training_corpus['class'].value_counts()\n",
    "print()\n",
    "print(\"Class distribution:\\n\", class_document_count)\n",
    "\n",
    "print()\n",
    "print(\"Size of training corpus = %d documents\" % len(training_corpus.index))\n",
    "print(\"Size of testing corpus = %d documents\" % len(testing_corpus.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "We'll select features using information gain, as described in Section 2.2 of [this paper](http://nyc.lti.cs.cmu.edu/yiming/Publications/yang-icml97.pdf). The information gain for any token w is:\n",
    "\n",
    "$$\n",
    "G(w) = -\\sum\\limits_{i=1}^m Pr(c_i) * log Pr(c_i) \\\\\n",
    "+ Pr(w) \\sum\\limits_{i=1}^m Pr(c_i \\mid w) * log Pr(c_i \\mid w) \\\\\n",
    "+ Pr(\\widetilde{w}) \\sum\\limits_{i=1}^m Pr(c_i \\mid \\widetilde{w}) * log Pr(c_i \\mid \\widetilde{w})\n",
    "$$\n",
    "\n",
    "First we'll calculate all possible features - the vocabulary of our training set. Then we'll compute the information gain for every one of those features, order them, and select the top 1000. Since we're just sorting the information gains by feature, the $-\\sum\\limits_{i=1}^m Pr(c_i) * log Pr(c_i)$ term which is constant across all features won't affect our results. Thus we won't bother computing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7769/7769 [00:03<00:00, 2554.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some example features:  ['28th', 'receivable', 'Huashan', 'HMOA', 'inactive', 'merchandiser', 'ART', 'gap', 'Larsen', 'Cahit']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# First figure out all possible features. In this case that's the vocabulary\n",
    "vocabulary = set()\n",
    "for _, document in tqdm(training_corpus.iterrows(), total=len(training_corpus), unit='document'):\n",
    "    for token in document['tokens']:\n",
    "        vocabulary.add(token)\n",
    "\n",
    "vocabulary = list(vocabulary)\n",
    "print(\"Some example features: \", vocabulary[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll compute the information gain for every feature in our vocabulary. We won't do this in a modular way since we need to optimize this part for speed. First for the conditional probabilities, we'll count for each (feature, class) pair how many documents of that class contain that feature (so binary counting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7769/7769 [00:47<00:00, 162.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "docs_with_feature = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for _, document in tqdm(training_corpus.iterrows(), total=len(training_corpus), unit='document'):  # for each document\n",
    "    tokens_binary = set(document['tokens'])  # binarize document tokens (for speed)\n",
    "    for feature in vocabulary:  # for every feature\n",
    "        if feature in tokens_binary:  # if feature shows up in document\n",
    "            docs_with_feature[feature][document['class']] += 1  # add 1 to (feature, class) count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next for the probabilities of each feature, we'll count the number of times each feature occurs, as well as the total number of tokens that are in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7769/7769 [00:04<00:00, 1654.26document/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total token count: 1253696\n",
      "Some example feature counts: [('INCOME', 19), ('28th', 1), ('receivable', 6), ('COUNTY', 3), ('HMOA', 1), ('merchandiser', 1), ('HILL', 4), ('ART', 4), ('Nordbanken', 6), ('SHIP', 14)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_count = 0  # total number of tokens across all documents\n",
    "feature_count = defaultdict(int)\n",
    "for _, document in tqdm(training_corpus.iterrows(), total=len(training_corpus), unit='document'):\n",
    "    total_count += len(document['tokens'])\n",
    "    \n",
    "    for token in document['tokens']:\n",
    "        feature_count[token] += 1\n",
    "        \n",
    "print(\"Total token count: {}\".format(total_count))\n",
    "print(\"Some example feature counts: {}\".format(list(feature_count.items())[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to put it all together and get the information gain per feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35247/35247 [00:01<00:00, 29348.50feature/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "set_of_classes = training_corpus['class'].unique()\n",
    "\n",
    "information_gain = defaultdict(int)\n",
    "for feature in tqdm(vocabulary, unit='feature'):\n",
    "    \n",
    "    pr_w = feature_count[feature] / total_count\n",
    "    pr_not_w = 1.0 - pr_w\n",
    "    \n",
    "    # A dictionary with (class, count) key-value pairs\n",
    "    docs_with_feature_in_class = docs_with_feature[feature]\n",
    "    \n",
    "    # The sum over all classes gives the total number of documents that had this feature\n",
    "    num_docs_with_feature = sum(docs_with_feature_in_class.values())\n",
    "    \n",
    "    # The total number of documents in the corpus minus the number of documents with this feature,\n",
    "    # gives the number of documents without this feature\n",
    "    num_docs_total = len(training_corpus)\n",
    "    num_docs_with_not_feature = num_docs_total - num_docs_with_feature\n",
    "    \n",
    "    for c in set_of_classes:\n",
    "        # Refer to the information gain formula\n",
    "        # We use add-1 smoothing to avoid errors with 0 counts\n",
    "        if (num_docs_with_feature == 0):\n",
    "            print(\"YUCK\")\n",
    "        pr_c_given_w = (docs_with_feature_in_class[c] + 1) / num_docs_with_feature\n",
    "        \n",
    "        if (num_docs_with_not_feature == 0):\n",
    "            print(\"OH NO\")\n",
    "        docs_with_not_feature_in_class_c = class_document_count[c] - docs_with_feature_in_class[c]\n",
    "        pr_c_given_not_w = (docs_with_not_feature_in_class_c + 1) / num_docs_with_not_feature\n",
    "        \n",
    "        if (pr_c_given_w == 0):\n",
    "            print(\"OH NOX\")\n",
    "        if (pr_c_given_not_w == 0):\n",
    "            print(\"OH NOZ\")\n",
    "        feature_class_info = pr_c_given_w * np.log(pr_c_given_w)\n",
    "        not_feature_class_info = pr_c_given_not_w * np.log(pr_c_given_not_w)\n",
    "        \n",
    "        information_gain[feature] += (pr_w * feature_class_info) + (pr_not_w * not_feature_class_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to sort and grab the top 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features: [';', '&', 'lt', '>', 'cts', '000', 'vs', 'company', 'mln', 'dlrs']\n"
     ]
    }
   ],
   "source": [
    "sorted_features = sorted(information_gain, key=information_gain.get)\n",
    "\n",
    "top_1000_features = sorted_features[:1000]\n",
    "print(\"Top 10 features: {}\".format(top_1000_features[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Vectorization\n",
    "\n",
    "Now we'll need to convert each training document into a (featureset, label) tuple. A featureset is a dictionary with features as keys and feature counts as values. This is the format that nltk will want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7769/7769 [00:02<00:00, 3066.10document/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "train = []\n",
    "for _, document in tqdm(training_corpus.iterrows(), total=len(training_corpus), unit='document'):\n",
    "    featureset = dict(Counter(document['tokens']))\n",
    "    \n",
    "    train.append((featureset, str(document['class'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we'll convert each testing document into just a featureset. We'll hold onto the testing labels for validation later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3019/3019 [00:00<00:00, 3182.72document/s]\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "test_labels = []\n",
    "for _, document in tqdm(testing_corpus.iterrows(), total=len(testing_corpus), unit='document'):\n",
    "    featureset = dict(Counter(document['tokens']))\n",
    "    \n",
    "    test.append(featureset)\n",
    "    test_labels.append(str(document['class']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Maximum Entropy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import maxent\n",
    "\n",
    "encoding = maxent.TypedMaxentFeatureEncoding.train(\n",
    "    train, count_cutoff=3, alwayson_features=True)\n",
    "\n",
    "classifier = maxent.MaxentClassifier.train(\n",
    "    train, bernoulli=False, encoding=encoding, trace=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.classify_many(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predicted positives: 0\n",
      "Number of true positives: 0\n"
     ]
    }
   ],
   "source": [
    "predictions = np.array(predictions)\n",
    "labels = np.array(test_labels)\n",
    "\n",
    "POSITIVE_CLASS = '1'\n",
    "NEGATIVE_CLASS = '-1'\n",
    "\n",
    "predicted_positives = (predictions == POSITIVE_CLASS).sum()\n",
    "\n",
    "true_positives = 0\n",
    "for i in range(len(predictions)):\n",
    "    # positive prediction and positive label\n",
    "    if predictions[i] == POSITIVE_CLASS and labels[i] == POSITIVE_CLASS:\n",
    "        true_positives += 1\n",
    "        \n",
    "print(\"Number of predicted positives: {}\".format(predicted_positives))\n",
    "print(\"Number of true positives: {}\".format(true_positives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predicted negatives: 3019\n",
      "Number of true negatives: 2840\n"
     ]
    }
   ],
   "source": [
    "predicted_negatives = (predictions == NEGATIVE_CLASS).sum()\n",
    "\n",
    "true_negatives = 0\n",
    "for i in range(len(predictions)):\n",
    "    # negative prediction and negative label\n",
    "    if predictions[i] == NEGATIVE_CLASS and labels[i] == NEGATIVE_CLASS:\n",
    "        true_negatives += 1\n",
    "        \n",
    "print(\"Number of predicted negatives: {}\".format(predicted_negatives))\n",
    "print(\"Number of true negatives: {}\".format(true_negatives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = nan\n",
      "Recall = 0.9407088439880755\n",
      "F1 = nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# reference: https://en.wikipedia.org/wiki/F1_score\n",
    "\n",
    "precision = true_positives / predicted_positives\n",
    "\n",
    "recall = true_negatives / predicted_negatives\n",
    "\n",
    "F1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Precision = {}\".format(precision))\n",
    "print(\"Recall = {}\".format(recall))\n",
    "print(\"F1 = {}\".format(F1_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
