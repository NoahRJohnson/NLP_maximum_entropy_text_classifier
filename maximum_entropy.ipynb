{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximum Entropy Text Classifier\n",
    "\n",
    "Classifying Reuters articles following [this](http://tongzhang-ml.org/papers/ir01_textcat.pdf) paper by Zhang and Oles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "We'll use the nltk.corpus.reuters corpus of news articles.\n",
    "\n",
    "The Reuters Corpus contains 10,788 news documents totaling 1.3 million words. The documents have been classified into 90 topics, and grouped into training and testing sets.\n",
    "\n",
    "We are going to choose a single category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10788/10788 [00:00<00:00, 30104.10article/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class                                             tokens\n",
      "   -1  (BAHIA, COCOA, REVIEW, Showers, continued, thr...\n",
      "   -1  (COMPUTER, TERMINAL, SYSTEMS, &, lt, ;, CPML, ...\n",
      "   -1  (N, ., Z, ., TRADING, BANK, DEPOSIT, GROWTH, R...\n",
      "   -1  (NATIONAL, AMUSEMENTS, AGAIN, UPS, VIACOM, &, ...\n",
      "   -1  (ROGERS, &, lt, ;, ROG, >, SEES, 1ST, QTR, NET...\n",
      "\n",
      "Size of training corpus = 7769 documents\n",
      "Size of testing corpus = 3019 documents\n",
      "\n",
      "Training corpus class distribution:\n",
      " -1    7231\n",
      " 1     538\n",
      "Name: class, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import reuters\n",
    "from tqdm import tqdm\n",
    "\n",
    "CHOSEN_CATEGORY = 'money-fx'\n",
    "\n",
    "training_articles = []\n",
    "training_labels = []\n",
    "testing_articles = []\n",
    "testing_labels = []\n",
    "\n",
    "# Loop over every document in the corpus\n",
    "for fileid in tqdm(reuters.fileids(), unit='article'):\n",
    "    \n",
    "    # Binary categorization\n",
    "    if CHOSEN_CATEGORY in reuters.categories(fileid):\n",
    "        label = 1\n",
    "    else:\n",
    "        label = -1\n",
    "\n",
    "    # Extract list of tokens for this document\n",
    "    article = reuters.words(fileid)\n",
    "    \n",
    "    # Put data in train or test set\n",
    "    if 'training' in fileid:\n",
    "        training_articles.append(article)\n",
    "        training_labels.append(label)\n",
    "    elif 'test' in fileid:\n",
    "        testing_articles.append(article)\n",
    "        testing_labels.append(label)\n",
    "    else:\n",
    "        print(\"Unrecognized document %s\" % fileid)\n",
    "\n",
    "# Create Pandas data frames\n",
    "training_corpus = pd.DataFrame({'tokens': training_articles, 'class': training_labels})\n",
    "testing_corpus = pd.DataFrame({'tokens': testing_articles, 'class': testing_labels})\n",
    "\n",
    "print(training_corpus.head().to_string(index=False))\n",
    "\n",
    "print()\n",
    "print(\"Size of training corpus = %d documents\" % len(training_corpus.index))\n",
    "print(\"Size of testing corpus = %d documents\" % len(testing_corpus.index))\n",
    "\n",
    "class_document_count = training_corpus['class'].value_counts()\n",
    "print()\n",
    "print(\"Training corpus class distribution:\\n\", class_document_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "We'll select features using information gain, as described in Section 2.2 of [this paper](http://nyc.lti.cs.cmu.edu/yiming/Publications/yang-icml97.pdf). The information gain for any token w is:\n",
    "\n",
    "$$\n",
    "G(w) = -\\sum\\limits_{i=1}^m Pr(c_i) * log Pr(c_i) \\\\\n",
    "+ Pr(w) \\sum\\limits_{i=1}^m Pr(c_i \\mid w) * log Pr(c_i \\mid w) \\\\\n",
    "+ Pr(\\widetilde{w}) \\sum\\limits_{i=1}^m Pr(c_i \\mid \\widetilde{w}) * log Pr(c_i \\mid \\widetilde{w})\n",
    "$$\n",
    "\n",
    "First we'll calculate all possible features - the vocabulary of our training set. Then we'll compute the information gain for every one of those features, order them, and select the top 1000. Since we're just sorting the information gains by feature, the $-\\sum\\limits_{i=1}^m Pr(c_i) * log Pr(c_i)$ term which is constant across all features won't affect our results. Thus we won't bother computing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7769/7769 [00:02<00:00, 2722.74document/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some example features:  ['pointing', 'Steels', 'thin', 'houseware', 'bills', 'Number', 'BI', '091', 'POSTINGS', 'renewals']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# First figure out all possible features. In this case that's the vocabulary\n",
    "vocabulary = set()\n",
    "for _, document in tqdm(training_corpus.iterrows(), total=len(training_corpus), unit='document'):\n",
    "    for token in document['tokens']:\n",
    "        vocabulary.add(token)\n",
    "\n",
    "vocabulary = list(vocabulary)\n",
    "print(\"Some example features: \", vocabulary[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll compute the information gain for every feature in our vocabulary. We won't do this in a modular way since we need to optimize this part for speed. First for the conditional probabilities, we'll count for each (feature, class) pair how many documents of that class contain that feature (so binary counting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7769/7769 [00:38<00:00, 199.65document/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "docs_with_feature = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for _, document in tqdm(training_corpus.iterrows(), total=len(training_corpus), unit='document'):  # for each document\n",
    "    tokens_binary = set(document['tokens'])  # binarize document tokens (for speed)\n",
    "    for feature in vocabulary:  # for every feature\n",
    "        if feature in tokens_binary:  # if feature shows up in document\n",
    "            docs_with_feature[feature][document['class']] += 1  # add 1 to (feature, class) count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next for the probabilities of each feature, we'll count the number of times each feature occurs, as well as the total number of tokens that are in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7769/7769 [00:02<00:00, 3051.77document/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total token count: 1253696\n",
      "Some example feature counts: [('pointing', 3), ('the', 43203), ('Steels', 1), ('thin', 8), ('Kizito', 2), ('houseware', 1), ('processing', 74), ('average', 424), ('kwacha', 21), ('bills', 186)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_count = 0  # total number of tokens across all documents\n",
    "feature_count = defaultdict(int)\n",
    "for _, document in tqdm(training_corpus.iterrows(), total=len(training_corpus), unit='document'):\n",
    "    total_count += len(document['tokens'])\n",
    "    \n",
    "    for token in document['tokens']:\n",
    "        feature_count[token] += 1\n",
    "        \n",
    "print(\"Total token count: {}\".format(total_count))\n",
    "print(\"Some example feature counts: {}\".format(list(feature_count.items())[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to put it all together and get the information gain per feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35247/35247 [00:01<00:00, 28488.31feature/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "set_of_classes = training_corpus['class'].unique()\n",
    "\n",
    "information_gain = defaultdict(int)\n",
    "for feature in tqdm(vocabulary, unit='feature'):\n",
    "    \n",
    "    pr_w = feature_count[feature] / total_count\n",
    "    pr_not_w = 1.0 - pr_w\n",
    "    \n",
    "    # A dictionary with (class, count) key-value pairs\n",
    "    docs_with_feature_in_class = docs_with_feature[feature]\n",
    "    \n",
    "    # The sum over all classes gives the total number of documents that had this feature\n",
    "    num_docs_with_feature = sum(docs_with_feature_in_class.values())\n",
    "    \n",
    "    # The total number of documents in the corpus minus the number of documents with this feature,\n",
    "    # gives the number of documents without this feature\n",
    "    num_docs_total = len(training_corpus)\n",
    "    num_docs_with_not_feature = num_docs_total - num_docs_with_feature\n",
    "    \n",
    "    for c in set_of_classes:\n",
    "        # Refer to the information gain formula\n",
    "        # We use add-1 smoothing to avoid errors with 0 counts\n",
    "        if (num_docs_with_feature == 0):\n",
    "            print(\"YUCK\")\n",
    "        pr_c_given_w = (docs_with_feature_in_class[c] + 1) / num_docs_with_feature\n",
    "        \n",
    "        if (num_docs_with_not_feature == 0):\n",
    "            print(\"OH NO\")\n",
    "        docs_with_not_feature_in_class_c = class_document_count[c] - docs_with_feature_in_class[c]\n",
    "        pr_c_given_not_w = (docs_with_not_feature_in_class_c + 1) / num_docs_with_not_feature\n",
    "        \n",
    "        if (pr_c_given_w == 0):\n",
    "            print(\"OH NOX\")\n",
    "        if (pr_c_given_not_w == 0):\n",
    "            print(\"OH NOZ\")\n",
    "        feature_class_info = pr_c_given_w * np.log(pr_c_given_w)\n",
    "        not_feature_class_info = pr_c_given_not_w * np.log(pr_c_given_not_w)\n",
    "        \n",
    "        information_gain[feature] += (pr_w * feature_class_info) + (pr_not_w * not_feature_class_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to sort and grab the top 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 features: [';', '&', 'lt', '>', 'cts', '000', 'vs', 'company', 'mln', 'dlrs']\n"
     ]
    }
   ],
   "source": [
    "sorted_features = sorted(information_gain, key=information_gain.get)\n",
    "\n",
    "top_1000_features = sorted_features[:1000]\n",
    "print(\"Top 10 features: {}\".format(top_1000_features[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Vectorization\n",
    "\n",
    "Now we'll need to convert each training document into a (featureset, label) tuple. A featureset is a dictionary with features as keys and feature counts as values. This is the format that nltk will want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7769/7769 [00:02<00:00, 2809.35document/s]\n"
     ]
    }
   ],
   "source": [
    "top_1000_features = set(top_1000_features)  # for speed of 'in' operator\n",
    "\n",
    "train = []\n",
    "for _, document in tqdm(training_corpus.iterrows(), total=len(training_corpus), unit='document'):\n",
    "    \n",
    "    featureset = defaultdict(int)\n",
    "    for feature in document['tokens']:\n",
    "        if feature in top_1000_features:\n",
    "            featureset[feature] += 1\n",
    "            \n",
    "    label = str(document['class'])\n",
    "\n",
    "    train.append((featureset, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we'll convert each testing document into just a featureset. We'll hold onto the testing labels for validation later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3019/3019 [00:01<00:00, 2243.05document/s]\n"
     ]
    }
   ],
   "source": [
    "test = []\n",
    "test_labels = []\n",
    "for _, document in tqdm(testing_corpus.iterrows(), total=len(testing_corpus), unit='document'):\n",
    "\n",
    "    featureset = defaultdict(int)\n",
    "    for feature in document['tokens']:\n",
    "        if feature in top_1000_features:\n",
    "            featureset[feature] += 1\n",
    "    \n",
    "    label = str(document['class'])\n",
    "    \n",
    "    test.append(featureset)\n",
    "    test_labels.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Maximum Entropy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.classify import maxent\n",
    "\n",
    "encoding = maxent.TypedMaxentFeatureEncoding.train(\n",
    "    train, count_cutoff=3, alwayson_features=True)\n",
    "\n",
    "classifier = maxent.MaxentClassifier.train(\n",
    "    train, bernoulli=False, encoding=encoding, trace=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.classify_many(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predicted positives: 106\n",
      "Number of true positives: 27\n"
     ]
    }
   ],
   "source": [
    "predictions = np.array(predictions)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "POSITIVE_CLASS = '1'\n",
    "NEGATIVE_CLASS = '-1'\n",
    "\n",
    "predicted_positives = (predictions == POSITIVE_CLASS).sum()\n",
    "\n",
    "true_positives = 0\n",
    "for i in range(len(predictions)):\n",
    "    # positive prediction and positive label\n",
    "    if predictions[i] == POSITIVE_CLASS and test_labels[i] == POSITIVE_CLASS:\n",
    "        true_positives += 1\n",
    "        \n",
    "print(\"Number of predicted positives: {}\".format(predicted_positives))\n",
    "print(\"Number of true positives: {}\".format(true_positives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predicted negatives: 2913\n",
      "Number of true negatives: 2761\n"
     ]
    }
   ],
   "source": [
    "predicted_negatives = (predictions == NEGATIVE_CLASS).sum()\n",
    "\n",
    "true_negatives = 0\n",
    "for i in range(len(predictions)):\n",
    "    # negative prediction and negative label\n",
    "    if predictions[i] == NEGATIVE_CLASS and test_labels[i] == NEGATIVE_CLASS:\n",
    "        true_negatives += 1\n",
    "        \n",
    "print(\"Number of predicted negatives: {}\".format(predicted_negatives))\n",
    "print(\"Number of true negatives: {}\".format(true_negatives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.25471698113207547\n",
      "Recall = 0.94782011671816\n",
      "F1 = 0.4015275357713221\n"
     ]
    }
   ],
   "source": [
    "# reference: https://en.wikipedia.org/wiki/F1_score\n",
    "\n",
    "precision = true_positives / predicted_positives\n",
    "\n",
    "recall = true_negatives / predicted_negatives\n",
    "\n",
    "F1_score = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Precision = {}\".format(precision))\n",
    "print(\"Recall = {}\".format(recall))\n",
    "print(\"F1 = {}\".format(F1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we got some results. The recall is pretty good, but the precision doesn't look great. This makes some sense because our data set is skewed - there are more negative examples than positive ones. Let's explore that real quick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(test_labels.astype(np.int32))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples in test set: 179\n",
      "Number of negative samples in test set: 2840\n",
      "Recall of trivial model that always classifies input documents as negative: 0.9407088439880755\n"
     ]
    }
   ],
   "source": [
    "num_positive_test_samples = (test_labels == '1').sum()\n",
    "num_negative_test_samples = (test_labels == '-1').sum()\n",
    "\n",
    "print(\"Number of positive samples in test set: {}\".format(num_positive_test_samples))\n",
    "print(\"Number of negative samples in test set: {}\".format(num_negative_test_samples))\n",
    "print(\"Recall of trivial model that always classifies input documents as negative: {}\".format(num_negative_test_samples / (num_positive_test_samples + num_negative_test_samples)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so it looks like if we just always classified input documents as negative, then we would have a recall of 94.07%. That's very close to our model's recall of 94.78%. But hey, at least our model is marginally better than nothing, and the precision of our model is better than trivial model's 0%. Our model correctly classifies positive documents 25.47% of the time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
